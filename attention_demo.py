# -*- coding: utf-8 -*-
"""Attention Demo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Eoi3PSgEPj2R9stcm8qb_dHUv_aB0quI
"""

from google.colab import drive
drive.mount('/content/drive/')

import os
import sys
import argparse
import cv2
import random
import colorsys
import requests
from io import BytesIO

# Find the excersize path dynamically
folder_name = 'Final Project'

# Start searching for the folder in the mounted Google Drive
base_dir = "/content/drive/"
folder_path = None

# Walk through the Google Drive to locate the folder
for root, dirs, files in os.walk(base_dir):
    if folder_name in dirs:
        folder_path = os.path.join(root, folder_name)
        break

if folder_path is None:
    raise FileNotFoundError(f"Folder '{folder_name}' not found in Google Drive!")

print(f"Found '{folder_name}' folder at: {folder_path}")

# Commented out IPython magic to ensure Python compatibility.
import skimage.io
from skimage.measure import find_contours
import matplotlib.pyplot as plt
from matplotlib.patches import Polygon
import torch
import torch.nn as nn
import torchvision
from torchvision import transforms as pth_transforms
import numpy as np
from PIL import Image as Image
# %cd /content/drive/My Drive/Deep Learning/Final Project/dinov2
from dinov2.models.vision_transformer import vit_small, vit_large

!ls "/content/drive/My Drive/Deep Learning/Final Project/dinov2"

if __name__ == '__main__':
    image_size = (952, 952)
    output_dir = '.'
    patch_size = 14

    device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")

    model = torch.hub.load("facebookresearch/dinov2", "dinov2_vits14").to(device)

    for p in model.parameters():
        p.requires_grad = False
    model.to(device)
    model.eval()

    img = Image.open('Quad2.jpeg')
    img = img.convert('RGB')
    transform = pth_transforms.Compose([
        pth_transforms.Resize(image_size),
        pth_transforms.ToTensor(),
        pth_transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
    ])
    img = transform(img)
    print(img.shape)

    # make the image divisible by the patch size
    w, h = img.shape[1] - img.shape[1] % patch_size, img.shape[2] - img.shape[2] % patch_size
    img = img[:, :w, :h].unsqueeze(0)

    w_featmap = img.shape[-2] // patch_size
    h_featmap = img.shape[-1] // patch_size

    print(img.shape)

    attentions = model.get_last_self_attention(img.to(device))

    nh = attentions.shape[1] # number of head

    # we keep only the output patch attention
    # for every patch
    attentions = attentions[0, :, 0, 1:].reshape(nh, -1)
    # weird: one pixel gets high attention over all heads?
    print(torch.max(attentions, dim=1))
    attentions[:, 283] = 0

    attentions = attentions.reshape(nh, w_featmap, h_featmap)
    attentions = nn.functional.interpolate(attentions.unsqueeze(0), scale_factor=patch_size, mode="nearest")[0].cpu().numpy()
    temp2 = attentions[:,50:, :]

    # save attentions heatmaps
    os.makedirs(output_dir, exist_ok=True)

    for j in range(nh):
        fname = os.path.join(output_dir, "Quad" + str(j) + ".png")
        plt.imsave(fname=fname, arr=temp2[j], format='png')
        print(f"{fname} saved.")