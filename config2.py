# -*- coding: utf-8 -*-
"""config2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XkIbWr4eud1AIglCnu_zIDonxM-lnf96
"""

import torch
from dataclasses import dataclass

@dataclass
class Config:
    # Model Parameters
    embedding_model: str = "vits14"

    # Training Parameters
    hidden_size1: int = 256
    hidden_size2: int = 128
    num_classes: int = 3
    dropout: float = 0.5
    init_weights: float = 0.05
    batch_size: int = 32
    epochs: int = 20
    learning_rate: float = 0.001
    reg: float = 1e-4

    # Label Mapping Dictionary
    label_dict: dict = None

    # Miscellaneous
    seed: int = 42
    device: str = "cuda" if torch.cuda.is_available() else "cpu"
    data_path: str = "datasets"
    model_save_path: str = "saved_models"
    embedding_save_path: str = "saved_models/embeddings.pth"
    unzip_files: bool = True
    save_path: str = "saved_models"
    train_coef: float = 0.8 # percential of data going to train, the rest is for validation

    # Embedding Sizes
    embedding_sizes: dict = None

    def __post_init__(self):
        """Initialize computed fields."""
        if self.label_dict is None:
            self.label_dict = {"UAV": 0, "QUADCOPTER": 1, "HELICOPTER": 2}
        if self.embedding_sizes is None:
            self.embedding_sizes = {"vits14": 384, "vitb14": 768, "vitl14": 1024}

    @property
    def input_size(self):
        """Dynamically updates input_size based on the current embedding_model."""
        return self.embedding_sizes[self.embedding_model]


args = Config()