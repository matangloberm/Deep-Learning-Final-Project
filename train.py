# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fMYCjICCqECRLjiY6LgYq-iZpGtnHq5M
"""

import torch
import torch.optim as optim
import torch.nn as nn
from model import FullyConnected
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import config2 as config
import importlib
import sys
import os
import matplotlib.pyplot as plt





def train_model(train_loader, val_loader):
    """Train the Fully Connected Model."""
    model = FullyConnected().to(config.args.device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=config.args.learning_rate, weight_decay = config.args.reg)
    train_acc_vec = []
    val_acc_vec = []


    for epoch in range(config.args.epochs):
        model.train()
        total_loss = 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(config.args.device), labels.to(config.args.device, dtype=torch.long)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        avg_train_loss, avg_train_acc = validate_model(model, train_loader)
        val_loss, val_acc = validate_model(model, val_loader)
        print(f"Epoch {epoch+1}/{config.args.epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")

        train_acc_vec.append(avg_train_acc)
        val_acc_vec.append(val_acc)

    plot_convergence(train_acc_vec, val_acc_vec)

    print(f"saving model to {config.args.model_save_path}")
    path = os.path.join(config.args.model_save_path, "fc.pth")
    torch.save(model.state_dict(),path)

    print(f"✅ Model saved in {path}")

def evaluate_model(test_loader):
    """Evaluate the trained model."""
    path = os.path.join(config.args.model_save_path, "fc.pth")
    model = FullyConnected().to(config.args.device)
    model.load_state_dict(torch.load(path))
    model.eval()

    correct, total = 0, 0
    all_predictions, all_labels = [], []
    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(config.args.device), labels.to(config.args.device)
            outputs = model(inputs)
            predictions = torch.argmax(outputs, dim=1)
            correct += (predictions == labels).sum().item()
            total += labels.size(0)
            all_predictions.extend(predictions.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())


    num_classes = config.args.num_classes

    display_labels = [str(i) for i in range(num_classes)]

    conf_matrix = confusion_matrix(all_labels, all_predictions)

    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=display_labels)

    disp.plot(cmap="Blues")

    accuracy = 100 * correct / total
    print(f"✅ Test Accuracy: {accuracy:.2f}%")




    #return accuracy, conf_matrix

def validate_model(model, val_loader):
    model.eval()
    val_loss , correct, total = 0, 0, 0
    criterion = nn.CrossEntropyLoss()
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(config.args.device), labels.to(config.args.device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            predictions = torch.argmax(outputs, dim=1)
            correct += (predictions == labels).sum().item()
            total += labels.size(0)
    avg_val_loss = val_loss / len(val_loader)
    val_acc = 100 * correct / total
    return avg_val_loss, val_acc


def plot_convergence(train_acc, val_acc):
    plt.figure(figsize=(8, 5))
    plt.plot(train_acc, label="Training Accuracy", marker="o")
    plt.plot(val_acc, label="Validation Accuracy", marker="s", linestyle="dashed")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.title("Model Convergence Graph")
    plt.legend()
    plt.grid()
    plt.show()