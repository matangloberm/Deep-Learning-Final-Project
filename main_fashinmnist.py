# -*- coding: utf-8 -*-
"""main FashinMNIST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Dczw9IWmoyn6oZFYs2eebploZhkJs_Pi
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import random_split, DataLoader
#!pip install argparse

folder_name = 'Final Project'
base_dir = "/content/drive/"
folder_path = None


for root, dirs, files in os.walk(base_dir):
    if folder_name in dirs:
        folder_path = os.path.join(root, folder_name)
        break

if folder_path is None:
    raise FileNotFoundError(f"Folder '{folder_name}' not found in Google Drive!")


os.chdir(folder_path)
print(f"Working directory set to: {folder_path}")


!jupyter nbconvert --to python config2.ipynb --output=config2
!jupyter nbconvert --to python data_loader.ipynb --output=data_loader
!jupyter nbconvert --to python train.ipynb --output=train
!jupyter nbconvert --to python utils.ipynb --output=utils
!jupyter nbconvert --to python embedding_model.ipynb --output=embedding_model
!jupyter nbconvert --to python embedding_extractor.ipynb --output=embedding_extractor
!jupyter nbconvert --to python model.ipynb --output=model

import os

expected_files = ["config.py", "data_loader.py", "train.py", "utils.py", "embedding_model.py", "embedding_extractor.py"]

for file in expected_files:
    if os.path.exists(file):
        print(f"✅ {file} exists")
    else:
        print(f"{file} is missing!")

import shutil

notebooks = ["config.py", "data_loader.py", "train.py", "utils.py", "embedding_model.py", "embedding_extractor.py"]

for nb in notebooks:
    src = f"/content/{nb}"  # Source path where `.py` files are generated
    dest = os.path.join(folder_path, nb)  # Destination inside the `Final Project` folder

    if os.path.exists(src):
        shutil.move(src, dest)
        print(f"Moved {nb} to {folder_path}")


import sys
sys.path.append(folder_path)
print("Project folder added to Python path")

if "config" in sys.modules:
    del sys.modules["config"]
import config2 as config
data_path = os.path.join(folder_path, "AugmentedData/data8")
print(f"✅ Data path set to: {data_path}")
model = "vitl14"

config.args.embedding_model = model
config.args.data_path = data_path
config.args.model_save_path = os.path.join(folder_path, "saved_models", model, "FashionMNIST") # specifies the folder of the trained fully connected model
config.args.save_path = os.path.join(folder_path, "saved_embeddings", model) # specifies the folder of the embedded samples
config.args.embedding_save_path = os.path.join(config.args.save_path, "embeddings_FashionMNIST")
config.args.unzip_files =False
config.args.batch_size = 32
config.args.num_classes = 10

if config.args.embedding_model == "vitb14":
    config.args.hidden_size1 = 768
    config.args.hidden_size2 = 256

    config.args.dropout1 = 0.5
    config.args.dropout2 = 0.4

    config.args.init_weights = 0.05
    config.args.reg = 5e-4
    config.args.learning_rate = 5e-4

    config.args.epochs = 25

elif config.args.embedding_model == "vitl14":
    config.args.hidden_size1 = 768
    config.args.hidden_size2 = 256

    config.args.dropout1 = 0.3
    config.args.dropout2 = 0.2

    config.args.init_weights = 0.02  # Even lower for large models
    config.args.reg = 1e-4
    config.args.learning_rate = 2e-4

    config.args.epochs = 15
else:
    config.args.hidden_size1 = 256
    config.args.hidden_size2 = 64

    config.args.dropout1 = 0.6
    config.args.dropout2 = 0.5

    config.args.init_weights = 0.1
    config.args.reg = 1e-3
    config.args.learning_rate = 1e-3





#if not os.path.exists(config.args.save_path):
os.makedirs(config.args.save_path, exist_ok = True)
if os.path.exists(config.args.model_save_path) and not os.path.isdir(config.args.model_save_path):
    print(f"ERROR: `{config.args.model_save_path}` exists but is NOT a directory Deleting and recreating as a folder.")
    os.remove(config.args.model_save_path)  # Delete the misclassified file
    os.makedirs(config.args.model_save_path, exist_ok=True)  # Create as a proper directory
elif not os.path.exists(config.args.model_save_path):
  os.makedirs(config.args.model_save_path, exist_ok=True)  # Create normally if it doesn't exist


from data_loader import unzip_files, load_transformed_samples
from train import train_model, evaluate_model
from utils import set_random_seed
from embedding_model import upload_model

embedding_model = upload_model().to(config.args.device)
print(f"Updated dataset path: {config.args.data_path}")

from data_loader import transform

from torch.utils.data import TensorDataset


def load_transformed_samples(dataset, label, embedding_model):
    """Processes FashionMNIST dataset, extracts embeddings using ViT, and saves embeddings."""

    all_embeddings, all_labels = [], []

    # Iterate over dataset directly (no file processing)
    for image, label in dataset:
        image = image.unsqueeze(0).to("cuda")  # Ensure batch dimension

        # Extract embeddings from ViT model
        with torch.no_grad():
            embedding = embedding_model(image).cpu().squeeze()

        all_embeddings.append(embedding)
        all_labels.append(label)  # Labels come from dataset

    # Convert list of embeddings to TensorDataset
    if all_embeddings:
        embeddings_tensor = torch.stack(all_embeddings)
        labels_tensor = torch.tensor(all_labels, dtype=torch.long)

        embeddings_data_set = TensorDataset(embeddings_tensor, labels_tensor)
        save_path = os.path.join(config.args.embedding_save_path, f"{label}.pt")

        # Ensure the directory exists
        if not os.path.exists(config.args.embedding_save_path):
            os.makedirs(config.args.embedding_save_path)
        torch.save(embeddings_data_set, save_path)
        print(f"Saved embeddings for '{label}' at: {save_path}")

        return embeddings_data_set
    else:
        print(f"No data found in dataset '{label}'")
        return None

full_train_dataset = torchvision.datasets.FashionMNIST(root="./data", train=True, transform=transform, download=True)

# Define Split Sizes
train_size = 10_000
val_size = 2_000
remaining = len(full_train_dataset) - (train_size + val_size)  # Remaining data to discard

# Split into Training (10K) & Validation (2K)
train_dataset, val_dataset, _ = random_split(full_train_dataset, [train_size, val_size, remaining])

# Load the Official Test Set
full_test_dataset = torchvision.datasets.FashionMNIST(root="./data", train=False, transform=transform, download=True)

# Split into Test Set (1K) & Discard Remaining
test_size = 1_000
test_dataset, _ = random_split(full_test_dataset, [test_size, len(full_test_dataset) - test_size])

train_dataset = load_transformed_samples(train_dataset, 'train', embedding_model)
val_dataset = load_transformed_samples(val_dataset, 'val', embedding_model)
test_dataset = load_transformed_samples(test_dataset, 'test', embedding_model)

# Convert to DataLoader
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.args.batch_size, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=config.args.batch_size, shuffle=False)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=config.args.batch_size, shuffle=False)

print(f"Training samples: {len(train_dataset)}")
print(f"Validation samples: {len(val_dataset)}")
print(f"Test samples: {len(test_dataset)}")

train_labels = [label for _, label in train_dataset]
print(f"Label Min: {min(train_labels)}, Max: {max(train_labels)}")

# Train and evaluate
train_model(train_loader, val_loader)
evaluate_model(test_loader)